import re
import pandas as pd
import streamlit as st

from parsers import parse_any
from utils.excel import to_xlsx_bytes

st.set_page_config(page_title="ë„ì„œ URL ìë™ì™„ì„±", layout="wide")

st.markdown(
    """
<style>
/* ë²„íŠ¼ í¬ê¸°/ë†’ì´ í†µì¼: 'ëˆ„ì  ì´ˆê¸°í™”' & 'ì—‘ì…€ ë‹¤ìš´ë¡œë“œ'ë¥¼ ì œëª© ë†’ì´ì™€ ë§ì¶¤ */
div[data-testid="stButton"] > button,
div[data-testid="stDownloadButton"] > button {
  height: 44px;
  font-size: 1rem;
  padding: 0.35rem 0.9rem;
}
/* í—¤ë”(3) ì œëª©ê³¼ ë²„íŠ¼ ì„¸ë¡œ ì •ë ¬ ë³´ì • */
.v-align-44 { line-height: 44px; margin: 0; padding: 0; }
</style>
""",
    unsafe_allow_html=True,
)

st.title("ğŸ“š ë„ì„œ ì •ë³´ ìë™ ì±„ì›€")
st.caption("URLì„ ì…ë ¥í•˜ê³  ë„ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ISBN/ë„ì„œëª…/ì €ì/ì¶œíŒì‚¬/ê°€ê²©ì´ ìë™ìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤. ê²°ê³¼ëŠ” ëˆ„ì í•´ ì—‘ì…€ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

with st.expander("âœ… ì§€ì› ì„œì  / ì‚¬ìš© ë°©ë²• / ì£¼ì˜", expanded=False):
    st.markdown(
        """
- ì§€ì›: **êµë³´ë¬¸ê³  / YES24 / ì•Œë¼ë”˜ / ì˜í’ë¬¸ê³ **
- ì‚¬ìš©:
  1) ì‚¬ìš©í•  ì„œì ì„ í† ê¸€ë¡œ ì„ íƒ  
  2) ìƒí’ˆ URLì„ í•œ ì¤„ì— í•˜ë‚˜ì”© ì…ë ¥(ì—¬ëŸ¬ ì¤„ ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥)  
  3) **ë„ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°** â†’ í…Œì´ë¸” ëˆ„ì   
  4) **ì—‘ì…€ ë‹¤ìš´ë¡œë“œ**  
- ì£¼ì˜:
  - ì¼ë¶€ ì„œì ì€ **ë™ì  ë Œë”ë§/ë´‡ ì°¨ë‹¨**ìœ¼ë¡œ ì¼ë°˜ ìš”ì²­ íŒŒì‹±ì´ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  - ì´ ì•±ì€ ê·¸ëŸ° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ **Playwright(í—¤ë“œë¦¬ìŠ¤ ë¸Œë¼ìš°ì €) ë°±ì—… íŒŒì‹±**ì„ ìë™ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
    )

if "rows" not in st.session_state:
    st.session_state.rows = []

if "urls_input" not in st.session_state:
    st.session_state.urls_input = ""

colA, colB = st.columns([1, 2])

with colA:
    st.subheader("1) ì„œì  ì„ íƒ")
    use_kyobo = st.toggle("êµë³´ë¬¸ê³ ", value=False)
    use_yes24 = st.toggle("YES24", value=False)
    use_aladin = st.toggle("ì•Œë¼ë”˜", value=False)
    use_yp = st.toggle("ì˜í’ë¬¸ê³ ", value=False)
    enabled_sites = {"KYobo": use_kyobo, "YES24": use_yes24, "ALADIN": use_aladin, "YPBOOKS": use_yp}

with colB:
    st.subheader("2) URL ì…ë ¥")
    urls_text = st.text_area(
        "í•œ ì¤„ì— í•˜ë‚˜ì”© ìƒí’ˆ URLì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.",
        key="urls_input",
        height=140,
        placeholder="""ì˜ˆ)
https://www.yes24.com/Product/Goods/168226997
https://product.kyobobook.co.kr/detail/S000218972540
https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=376765918
https://www.ypbooks.co.kr/books/202512185684862499?idKey=33""",
        on_change=_normalize_urls_input,
    )

    st.caption("TIP: URLì„ ë¶™ì—¬ë„£ìœ¼ë©´ ìë™ìœ¼ë¡œ í•œ ì¤„ì— í•˜ë‚˜ì”© ì •ë¦¬ë©ë‹ˆë‹¤. (ì—¬ëŸ¬ URL ë™ì‹œ ì…ë ¥ ê°€ëŠ¥)")
    run = st.button("ğŸš€ ë„ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°", type="primary")


def _normalize_urls_input():
    text = st.session_state.get("urls_input", "") or ""
    # ë¶™ì—¬ë„£ê¸° ì‹œ ê³µë°±/íƒ­ìœ¼ë¡œ ë“¤ì–´ì˜¨ URLë„ ìë™ìœ¼ë¡œ í•œ ì¤„ì— í•˜ë‚˜ì”© ì •ë¦¬ + ë§ˆì§€ë§‰ì— ê°œí–‰ ì¶”ê°€
    candidates = re.findall(r"https?://[^\s]+", text)
    cleaned = []
    for u in candidates:
        u = u.strip().strip('"').strip("'")
        u = u.rstrip(").,;")
        cleaned.append(u)
    out, seen = [], set()
    for u in cleaned:
        if u and u not in seen:
            seen.add(u)
            out.append(u)
    new_text = "\n".join(out)
    if new_text and not new_text.endswith("\n"):
        new_text += "\n"
    st.session_state["urls_input"] = new_text


def normalize_urls(text: str) -> list[str]:
    urls = []
    for line in (text or "").splitlines():
        line = line.strip()
        if not line:
            continue
        if not re.match(r"^https?://", line):
            continue
        urls.append(line)
    seen, out = set(), []
    for u in urls:
        if u in seen:
            continue
        seen.add(u)
        out.append(u)
    return out

def fmt_won(v):
    if v is None:
        return ""
    try:
        if pd.isna(v):
            return ""
    except Exception:
        pass
    try:
        return f"{int(v):,}ì›"
    except Exception:
        return str(v)

STATUS_KO = {"success": "ì„±ê³µ", "failed": "ì‹¤íŒ¨", "skipped": "ì œì™¸"}
PARSEMODE_KO = {"requests": "ìë™", "playwright": "ë¸Œë¼ìš°ì €", "skipped": "ì œì™¸", "unknown": "ì•Œìˆ˜ì—†ìŒ", "exception": "ì˜¤ë¥˜"}
COLUMN_KO = {
    "site": "ì„œì ", "url": "ìƒí’ˆ URL", "status": "ì²˜ë¦¬ìƒíƒœ", "isbn": "ISBN", "title": "ë„ì„œëª…",
    "author": "ì €ì", "publisher": "ì¶œíŒì‚¬", "list_price": "ì •ê°€", "sale_price": "íŒë§¤ê°€",
    "product_id": "ìƒí’ˆID", "parse_mode": "ì²˜ë¦¬ë°©ì‹", "error": "ì˜¤ë¥˜", "note": "ë¹„ê³ ",
}
SITE_KO = {"KYobo": "êµë³´ë¬¸ê³ ", "YES24": "YES24", "ALADIN": "ì•Œë¼ë”˜", "YPBOOKS": "ì˜í’ë¬¸ê³ "}

if run:
    urls = normalize_urls(urls_text)
    if not urls:
        st.warning("ìœ íš¨í•œ URLì´ ì—†ì–´ìš”. http(s)ë¡œ ì‹œì‘í•˜ëŠ” ìƒí’ˆ URLì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        progress = st.progress(0, text="íŒŒì‹± ì¤‘...")
        new_rows = []
        for i, url in enumerate(urls, start=1):
            new_rows.append(parse_any(url, enabled_sites=enabled_sites))
            progress.progress(i / len(urls), text=f"íŒŒì‹± ì¤‘... ({i}/{len(urls)})")
        progress.empty()

        existing = {str(r.get("isbn")).strip() for r in st.session_state.rows if r.get("isbn")}
        for r in new_rows:
            isbn = str(r.get("isbn")).strip() if r.get("isbn") else ""
            if isbn and isbn in existing:
                r["note"] = "âš  ì´ë¯¸ ì¶”ê°€ëœ ë„ì„œ"
            elif isbn:
                existing.add(isbn)

        st.session_state.rows.extend(new_rows)
        st.success(f"{len(new_rows)}ê°œ URLì„ ì²˜ë¦¬í–ˆì–´ìš”. ì•„ë˜ í…Œì´ë¸”ì— ëˆ„ì ë˜ì—ˆìŠµë‹ˆë‹¤.")

# 3) ëˆ„ì  ê²°ê³¼ (ì œëª© ì˜†ì— 'ëˆ„ì  ì´ˆê¸°í™”' + ì²˜ë¦¬ ì™„ë£Œ ì‹œ 'ì—‘ì…€ ë‹¤ìš´ë¡œë“œ' ë²„íŠ¼ í‘œì‹œ)
h1, h2, h3 = st.columns([1, 0.18, 0.32], gap="small")
with h1:
    st.markdown('<h3 class="v-align-44">3) ëˆ„ì  ê²°ê³¼</h3>', unsafe_allow_html=True)

with h2:
    clear2 = st.button("ğŸ§¹ ëˆ„ì  ì´ˆê¸°í™”", key="clear_accum")

# ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì€ ëˆ„ì  ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ë…¸ì¶œ (4) ì„¹ì…˜ ë¬¸êµ¬ëŠ” ì œê±°)
with h3:
    download_clicked = False  # placeholder

if clear2:
    st.session_state.rows = []
    st.toast("ëˆ„ì  ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í–ˆì–´ìš”.", icon="ğŸ§¹")
    st.rerun()

if st.session_state.rows:
    df_raw = pd.DataFrame(st.session_state.rows)

    # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ëˆ„ì  ì´ˆê¸°í™” ì˜†)
    xbytes = to_xlsx_bytes(df_raw)
    with h3:
        st.download_button(
            "â¬‡ï¸ ê²°ê³¼ ì—‘ì…€(.xlsx) ë‹¤ìš´ë¡œë“œ",
            data=xbytes,
            file_name="ë„ì„œ_ìë™ì™„ì„±_ê²°ê³¼.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="secondary",
            key="download_xlsx",
        )

    df_view = df_raw.copy()
    if "site" in df_view.columns:
        df_view["site"] = df_view["site"].map(SITE_KO).fillna(df_view["site"])
    if "status" in df_view.columns:
        df_view["status"] = df_view["status"].map(STATUS_KO).fillna(df_view["status"])
    if "parse_mode" in df_view.columns:
        df_view["parse_mode"] = df_view["parse_mode"].map(PARSEMODE_KO).fillna(df_view["parse_mode"])

    for c in ["list_price", "sale_price"]:
        if c in df_view.columns:
            df_view[c] = df_view[c].apply(fmt_won)

    df_view = df_view.rename(columns=COLUMN_KO)

    preferred_cols = ["ì„œì ","ìƒí’ˆ URL","ì²˜ë¦¬ìƒíƒœ","ISBN","ë„ì„œëª…","ì €ì","ì¶œíŒì‚¬","ì •ê°€","íŒë§¤ê°€","ë¹„ê³ ","ìƒí’ˆID","ì²˜ë¦¬ë°©ì‹","ì˜¤ë¥˜"]
    cols = [c for c in preferred_cols if c in df_view.columns] + [c for c in df_view.columns if c not in preferred_cols]
    st.dataframe(df_view[cols], use_container_width=True, hide_index=True)

    ok = df_raw[df_raw["status"] == "success"] if "status" in df_raw.columns else df_raw
    st.caption(f"ì„±ê³µ: {len(ok)} / ì „ì²´: {len(df_raw)}")
else:
    st.info("ì•„ì§ ëˆ„ì ëœ ë°ì´í„°ê°€ ì—†ì–´ìš”. URLì„ ì…ë ¥í•˜ê³  **ë„ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°**ë¥¼ ëˆŒëŸ¬ë³´ì„¸ìš”.")
